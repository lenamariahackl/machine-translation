{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/home/lena/Desktop/Application Project/src/ibm1.py'\n",
    "%run '/home/lena/Desktop/Application Project/src/ibm2.py'\n",
    "%run '/home/lena/Desktop/Application Project/src/pbmt.py'\n",
    "%run '/home/lena/Desktop/Application Project/src/utils.py'\n",
    "%run '/home/lena/Desktop/Application Project/src/test.py'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training IBM Model 1\n",
      "IBM Model 1 training finished.\n",
      "start training IBM Model 2\n",
      "step 25 of 25\n",
      "IBM Model 2 training finished.\n",
      "start training IBM Model 1\n",
      "step 25 of 25\n",
      "IBM Model 1 training finished.\n",
      "start training IBM Model 2\n",
      "step 25 of 25\n",
      "IBM Model 2 training finished.\n",
      "\n",
      "Compare my IBM Model 1 to nltk library:\n",
      "M ['das', 'Haus'] ['house', 'the', 'the'] 0-2 1-0\n",
      "M ['das', 'Buch'] ['the', 'the', 'book'] 0-1 1-2\n",
      "M ['ein', 'Buch'] ['a', 'book'] 0-0 1-1\n",
      "M ['Haus'] ['house'] 0-0\n",
      "All t values were correct.\n",
      "\n",
      "Compare my IBM Model 2 to nltk library:\n",
      "All t values were correct.\n",
      "wrong a: 0.9616751923277211 != 1e-12 for i 1  j 0  l_e 3  l_f 2\n",
      "wrong a: 0.9999999999996666 != 1e-12 for i 0  j 1  l_e 3  l_f 2\n",
      "wrong a: 0.9999999999989999 != 1e-12 for i 0  j 0  l_e 2  l_f 2\n",
      "wrong a: 0.9999999999989999 != 1e-12 for i 0  j 0  l_e 1  l_f 1\n",
      "\n",
      "Compare my IBM Model 2 to nltk library:\n",
      "All t values were correct.\n",
      "wrong a: 0.9999999403948587 != 1e-12 for i 1  j 0  l_e 2  l_f 3\n",
      "wrong a: 0.9999999999989999 != 1e-12 for i 0  j 0  l_e 2  l_f 2\n",
      "wrong a: 0.9999999999989999 != 1e-12 for i 0  j 0  l_e 1  l_f 1\n",
      "\n",
      "0 ['Haus'] ['a', 'book'] ohoh sum is supposed to be 1 :(\n",
      "p_IBM1( ['the'] | ['das'] ) = 0.9999999998977336\n",
      "p_IBM2( ['the'] | ['das'] ) = 0.9999999999987418\n",
      "p_IBM1( ['the', 'the', 'house', 'a', 'book'] | ['das', 'ein', 'Buch', 'Haus'] ) = 0.0010363550198966517\n",
      "p_IBM2( ['the', 'the', 'house', 'a', 'book'] | ['das', 'ein', 'Buch', 'Haus'] ) = 0.0\n",
      "p_IBM1( ['book', 'a'] | ['Buch', 'ein'] ) = 0.24028843017066198\n",
      "p_IBM2( ['book', 'a'] | ['Buch', 'ein'] ) = 0.9999999998971538\n",
      "p_IBM1( ['book', 'a'] | ['ein', 'Buch'] ) = 0.24028843017066198\n",
      "p_IBM2( ['book', 'a'] | ['ein', 'Buch'] ) = 3.999999999794307e-24\n",
      "p_IBM1( ['book', 'the'] | ['Buch', 'ein'] ) = 0.009695207822635986\n",
      "p_IBM2( ['book', 'the'] | ['Buch', 'ein'] ) = 1.008460602342486e-22\n",
      "p_IBM1( ['kgefw', 'fek'] | ['Buch', 'ein'] ) = 0.0\n",
      "p_IBM2( ['kgefw', 'fek'] | ['Buch', 'ein'] ) = 0.0\n",
      "IBM Model 1 : 66 % correct\n",
      "IBM Model 2 : 83 % correct\n"
     ]
    }
   ],
   "source": [
    "TEST = True \n",
    "nr_used_sentences = 100 #1800 for 1model,25steps  # of 688670 lines\n",
    "path = \"./src/Paralel Corpus/\"\n",
    "e, f = read_in_corpus(nr_used_sentences, path)\n",
    "\n",
    "training_split = 0.9\n",
    "e_train, e_test = split_dataset(e, training_split)\n",
    "f_train, f_test = split_dataset(f, training_split)\n",
    "\n",
    "if TEST:\n",
    "    # we don't use real data but instead [['house','the','the'],['the','the','book'],['a','book']] etc\n",
    "    e_train, f_train, all_alignments_train, e_test, f_test, all_alignments_test = initialize_test_sets()\n",
    "\n",
    "max_steps = 25\n",
    "\n",
    "t_e2f_ibm1 = EM_IBM_Model_1(e_train, f_train, max_steps-5)\n",
    "t_e2f, a_e2f = EM_IBM_Model_2(e_train, f_train, t_e2f_ibm1, max_steps)\n",
    "t_f2e_ibm1 = EM_IBM_Model_1(f_train, e_train, max_steps)\n",
    "t_f2e, a_f2e = EM_IBM_Model_2(f_train, e_train, t_f2e_ibm1, max_steps)\n",
    "print()\n",
    "\n",
    "if TEST:\n",
    "    compare_ibm_1(t_e2f_ibm1, max_steps, e_train, f_train)\n",
    "    print()\n",
    "    compare_ibm_2(t_e2f, max_steps, a_e2f, e_train, f_train)\n",
    "    print()\n",
    "    compare_ibm_2(t_f2e, max_steps, a_f2e, f_train, e_train)\n",
    "    print()\n",
    "\n",
    "sum = 0\n",
    "for i in range(len(f_train)):\n",
    "    if (i,4,2,2) in a_f2e:\n",
    "        sum += a[(i,4,2,2)]\n",
    "print(sum,f_train[i],e_train[2],'ohoh sum is supposed to be 1 :(')\n",
    "\n",
    "# Testing\n",
    "correct1 = 0\n",
    "correct2 = 0\n",
    "bool_test = [True, True, True, False, False, False] #correct prob values around[1, 0.7, 0.9, 0.1, 0.01, 0]\n",
    "for i in range(0, len(f_test)):\n",
    "    f = f_test[i]\n",
    "    e = e_test[i]\n",
    "    p1 = prob_e_given_f_1(e, f, 1, t_e2f_ibm1)\n",
    "    if (p1 > 0.5) == bool_test[i]: correct1 += 1\n",
    "    print('p_IBM1(', e, '|', f, ') =', p1)\n",
    "    p2 = prob_e_given_f_2(e, f, 1, t_e2f, a_e2f)\n",
    "    if (p2 > 0.5) == bool_test[i]: correct2 += 1\n",
    "    print('p_IBM2(', e, '|', f, ') =', p2)\n",
    "print('IBM Model 1 :', int(100*(correct1/len(f_test))),'% correct')\n",
    "print('IBM Model 2 :', int(100*(correct2/len(f_test))),'% correct')\n",
    "        \n",
    "#TODO alignment probabilities a gives different results than implementation in the nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right alignment :)\n",
      "\n",
      "['the', 'the', 'book'] ['das', 'Buch'] \n",
      "e2f     {0: 0, 1: 0, 2: 1} \n",
      "f2e     {0: 1, 1: 2} \n",
      "combine {0: [1, 0], 1: [2]}\n",
      "Returned wrong alignment {0: [1, 0], 1: [2]} \n",
      "Right alignment would be {0: [0, 1], 1: [2]} \n",
      "\n",
      "Right alignment :)\n",
      "\n",
      "Right alignment :)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Phrase - based MT\n",
    "#Input: sets of sentences e and f, t- and a-table in both directions\n",
    "#Output: alignments for sentences in sets\n",
    "def word_alignment(e, f, t_e2f, a_e2f, t_f2e, a_f2e):\n",
    "    all_a = {}\n",
    "    for si in range(0, len(f)):\n",
    "        e2f = viterbi_alignment(e[si], f[si], t_e2f, a_e2f)\n",
    "        f2e = viterbi_alignment(f[si], e[si], t_f2e, a_f2e)\n",
    "        a = combine(f2e, e2f)\n",
    "        if (a == all_alignments_train[si]): print('Right alignment :)\\n')\n",
    "        else: \n",
    "            print(e[si],f[si],'\\ne2f    ',e2f,'\\nf2e    ',f2e,'\\ncombine', a)\n",
    "            print('Returned wrong alignment',a,'\\nRight alignment would be',all_alignments_train[si],'\\n')\n",
    "        all_a[si] = a\n",
    "    return all_a\n",
    "\n",
    "# IBM Model 2 for word alignment\n",
    "all_a_train = word_alignment(e_train, f_train, t_e2f, a_e2f, t_f2e, a_f2e)\n",
    "#all_a_test = word_alignment(e_test, f_test, t_e2f, a_e2f, t_f2e, a_f2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts: {\"['house']\": {\"['Haus']\": 1}, \"['book']\": {\"['Buch']\": 1}} \n",
      "\n",
      "calculate PT_prob for ['house'] ['Haus'] = 1.0\n",
      "PT_prob(['house'], ['Haus']) = 1.0\n",
      "calculate PT_prob for ['the', 'house'] ['das', 'Haus'] = 0\n",
      "PT_prob(['the','house'], ['das','Haus']) = 0 \n",
      "\n",
      "count_grams\n",
      "LM_prob( a | book )= 0.5\n",
      "P( a | book ) should be high 0.5\n",
      "LM_prob( house | book )= 0.05\n",
      "P( house | book ) should be low 0.05\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-6fe5cf7d3c79>\", line 36, in <module>\n",
      "    prob = prob_e_given_f(e, f, alignment, counts, unigram_counts, bigram_counts)\n",
      "TypeError: prob_e_given_f() missing 1 required positional argument: 'aligned_phrases'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "AttributeError: module has no attribute '__name__'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "prob_e_given_f() missing 1 required positional argument: 'aligned_phrases'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "{['house']:{['Haus']:1}, (['house', 'the'], ['das', 'Haus']), (['house', 'the', 'the'], ['das', 'Haus']), (['the'], ['das']), (['the', 'the'], ['das']), (['the'], ['das', 'Buch']), (['the', 'the'], ['das', 'Buch']), (['the', 'the', 'book'], ['das', 'Buch']), (['a'], ['ein']), (['a', 'book'], ['ein', 'Buch']), (['book'], ['Buch']), (['house'], ['Haus'])]\n",
    "\n",
    "e_train = [['michael','assumes','that','he','will','stay','in','the','house']]\n",
    "f_train = [['michael','geht','davon','aus',',','dass','er','im','haus','bleibt']]\n",
    "all_a_train = {0:{0:[0],1:[1,2,3],2:[5],3:[6],4:[9],5:[9],6:[7],7:[7],8:[8]}}\n",
    "# all_a[a][b] alignment for b word in e for sentence a\n",
    "\"\"\"\n",
    "counts = phrase_extraction(e_train, f_train, all_a_train, 3)\n",
    "#counts = phrase_extraction(e_test, f_test, all_a_test, 3)\n",
    "print('counts:',counts,'\\n')\n",
    "\n",
    "#phrase translation table\n",
    "print('PT_prob([\\'house\\'], [\\'Haus\\']) =', PT_prob(['house'], ['Haus'], counts))\n",
    "print('PT_prob([\\'the\\',\\'house\\'], [\\'das\\',\\'Haus\\']) =', PT_prob(['the','house'],['das','Haus'],counts),'\\n')\n",
    "\n",
    "#bigram language model\n",
    "unigram_counts, bigram_counts = count_grams(e_test)\n",
    "#print('unigram_counts',unigram_counts,'\\n bigram_counts', bigram_counts,'\\n')\n",
    "\n",
    "prev = 'book'\n",
    "cur = 'a'\n",
    "print('P(',cur,'|',prev,') should be high',LM_prob(prev, cur, unigram_counts, bigram_counts))\n",
    "cur = 'house'\n",
    "print('P(',cur,'|',prev,') should be low', LM_prob(prev, cur, unigram_counts, bigram_counts))\n",
    "\n",
    "# TODO phrase-based statistical machine translation model\n",
    "# • the phrase translation table φ(f|e);\n",
    "# • the reordering model d;\n",
    "# • the language model pLM(e).\n",
    "# e_best = argmax_e prod_i φ(f|e) * d(start_i - end_i_min_1 - 1) * prod_i PLM(e_i|e_i_min_1)\n",
    "for sentence in range(0, len(all_alignments_test)):\n",
    "    f = f_test[sentence]\n",
    "    e = e_test[sentence]\n",
    "    alignment = all_alignments_test[sentence]\n",
    "    prob = prob_e_given_f(e, f, alignment, counts, unigram_counts, bigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODOS\n",
    "\n",
    "#TODO unaligned cases!\n",
    "#model null alignments, some word doesnt have a word to align to \n",
    "#> just align it with the highest probable one\n",
    "\n",
    "#debug ibm 2\n",
    "#IBM Model 2: How to calculate a correctly?\n",
    "#my a is 1 when it should be low :(\n",
    "#implementation exactly like in book\n",
    "#eg sum is supposed to always be 1\n",
    "#use ibm model 2 in slides\n",
    "#compare subresults if they are right, count, stotal etc\n",
    "#look into indexing, starting 0 / 1?\n",
    "\n",
    "# TODO translation probability is not working for phrases containing several words\n",
    "#p(e|f) for IBM Model 2: Gives result 4 should be 1?\n",
    "#is sum wrong maybe?\n",
    "#> compare with other implementations\n",
    "\n",
    "#calculating p(e|f) phrase based model\n",
    "\n",
    "#decoding > example target sentences - do we even need the test set?\n",
    "#&gen alignments or manual?\n",
    "\n",
    "#TODO save t, a in files & load them?\n",
    "\n",
    "#structure code more? classes ML model, so it's intuitive to execute\n",
    "\n",
    "#remove special chars preprocessing\n",
    "#Application: Preprocessing convert Turkish characters!\n",
    "#Remove non-ASCII characters\n",
    "#lowercase\n",
    "#multi-character whitespaces to a single whitespace character\n",
    "#Remove URLs, numbers, leading and trailing whitespaces\n",
    "\n",
    "#efficient n-gram with trie\n",
    "#only store ngrams above a certain count threshold eg 4 saving 90%\n",
    "# save a significant amount of memory if we only store terms with some minimum count.\n",
    "\n",
    "#calc how long stuff takes\n",
    "#look into efficiency issues, use hashing?\n",
    "# TODO For the estimation of the phrase translation probabilities, not all\n",
    "# phrase pairs have to be loaded into memory. It is possible to efficiently\n",
    "# estimate the probability distribution by storing and sorting the extracted\n",
    "# phrases on disk. Similarly, when using the translation table for the translation of a single sentence, only a small fraction of it is needed and may\n",
    "# be loaded on demand.\n",
    "# think about saving stuff in file\n",
    "# • Phrase translation table typically bigger than corpus\n",
    "# ... even with limits on phrase lengths (e.g., max 7 words)\n",
    "# → Too big to store in memory?\n",
    "# • Solution for training\n",
    "# – extract to disk, sort, construct for one source phrase at a time\n",
    "# • Solutions for decoding\n",
    "# – on-disk data structures with index for quick look-ups\n",
    "# – suffix arrays to create phrase pairs on demand\n",
    "# TODO use numpy for everything\n",
    "# maybe other data structure ['the','house']:[['das','Haus'],['ein','Haus']]\n",
    "# faster sometimes but slower if translation in other direction\n",
    "\n",
    "#do summary 09!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training IBM Model 1\n",
      "step 25 of 25\n",
      "IBM Model 1 training finished.\n",
      "start training IBM Model 2\n",
      "step 25 of 25\n",
      "IBM Model 2 training finished.\n",
      "start training IBM Model 1\n",
      "step 25 of 25\n",
      "IBM Model 1 training finished.\n",
      "start training IBM Model 2\n",
      "step 25 of 25\n",
      "IBM Model 2 training finished.\n",
      "{0: ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hallway', 'after', 'shaking', 'the', 'womans', 'hand'], 1: ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hall', 'while', 'shaking', 'hands', 'with', 'the', 'woman'], 2: ['the', 'man', 'got', 'it', 'and', 'put', 'the', 'cigarette', 'off', 'went', 'to', 'the', 'hallway', 'shaking', 'the', 'hand', 'of', 'the', 'woman']} ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hallway', 'after', 'shaking', 'the', 'womans', 'hand']\n",
      "IBM Model 1 :p( ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hallway', 'after', 'shaking', 'the', 'womans', 'hand'] | ['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı'] ) = 0.0\n",
      "IBM Model 2: p( ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hallway', 'after', 'shaking', 'the', 'womans', 'hand'] | ['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı'] ) = 0.0\n",
      "{0: ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hallway', 'after', 'shaking', 'the', 'womans', 'hand'], 1: ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hall', 'while', 'shaking', 'hands', 'with', 'the', 'woman'], 2: ['the', 'man', 'got', 'it', 'and', 'put', 'the', 'cigarette', 'off', 'went', 'to', 'the', 'hallway', 'shaking', 'the', 'hand', 'of', 'the', 'woman']} ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hall', 'while', 'shaking', 'hands', 'with', 'the', 'woman']\n",
      "IBM Model 1 :p( ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hall', 'while', 'shaking', 'hands', 'with', 'the', 'woman'] | ['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı'] ) = 0.0\n",
      "IBM Model 2: p( ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hall', 'while', 'shaking', 'hands', 'with', 'the', 'woman'] | ['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı'] ) = 0.0\n",
      "{0: ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hallway', 'after', 'shaking', 'the', 'womans', 'hand'], 1: ['the', 'man', 'understood', 'this', 'extinguished', 'his', 'cigarette', 'went', 'to', 'the', 'hall', 'while', 'shaking', 'hands', 'with', 'the', 'woman'], 2: ['the', 'man', 'got', 'it', 'and', 'put', 'the', 'cigarette', 'off', 'went', 'to', 'the', 'hallway', 'shaking', 'the', 'hand', 'of', 'the', 'woman']} ['the', 'man', 'got', 'it', 'and', 'put', 'the', 'cigarette', 'off', 'went', 'to', 'the', 'hallway', 'shaking', 'the', 'hand', 'of', 'the', 'woman']\n",
      "IBM Model 1 :p( ['the', 'man', 'got', 'it', 'and', 'put', 'the', 'cigarette', 'off', 'went', 'to', 'the', 'hallway', 'shaking', 'the', 'hand', 'of', 'the', 'woman'] | ['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı'] ) = 0.0\n",
      "IBM Model 2: p( ['the', 'man', 'got', 'it', 'and', 'put', 'the', 'cigarette', 'off', 'went', 'to', 'the', 'hallway', 'shaking', 'the', 'hand', 'of', 'the', 'woman'] | ['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı'] ) = 0.0\n",
      "{0: ['in', 'every', 'work', 'he', 'tried', 'he', 'struggled', 'and', 'was', 'working', 'in', 'the', 'railway', 'department', 'now'], 1: ['in', 'every', 'work', 'he', 'entered', 'he', 'came', 'across', 'a', 'struggle', 'so', 'now', 'he', 'switched', 'into', 'the', 'railroad', 'business'], 2: ['in', 'every', 'job', 'he', 'tried', 'he', 'was', 'misfortunate', 'and', 'now', 'he', 'switched', 'to', 'working', 'in', 'the', 'railroad', 'business'], 3: ['he', 'had', 'ruined', 'his', 'prospects', 'in', 'a', 'number', 'of', 'positions', 'and', 'was', 'now', 'serving', 'in', 'the', 'railway', 'department']} ['in', 'every', 'work', 'he', 'tried', 'he', 'struggled', 'and', 'was', 'working', 'in', 'the', 'railway', 'department', 'now']\n",
      "IBM Model 1 :p( ['in', 'every', 'work', 'he', 'tried', 'he', 'struggled', 'and', 'was', 'working', 'in', 'the', 'railway', 'department', 'now'] | ['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'] ) = 0.0\n",
      "IBM Model 2: p( ['in', 'every', 'work', 'he', 'tried', 'he', 'struggled', 'and', 'was', 'working', 'in', 'the', 'railway', 'department', 'now'] | ['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'] ) = 0.0\n",
      "{0: ['in', 'every', 'work', 'he', 'tried', 'he', 'struggled', 'and', 'was', 'working', 'in', 'the', 'railway', 'department', 'now'], 1: ['in', 'every', 'work', 'he', 'entered', 'he', 'came', 'across', 'a', 'struggle', 'so', 'now', 'he', 'switched', 'into', 'the', 'railroad', 'business'], 2: ['in', 'every', 'job', 'he', 'tried', 'he', 'was', 'misfortunate', 'and', 'now', 'he', 'switched', 'to', 'working', 'in', 'the', 'railroad', 'business'], 3: ['he', 'had', 'ruined', 'his', 'prospects', 'in', 'a', 'number', 'of', 'positions', 'and', 'was', 'now', 'serving', 'in', 'the', 'railway', 'department']} ['in', 'every', 'work', 'he', 'entered', 'he', 'came', 'across', 'a', 'struggle', 'so', 'now', 'he', 'switched', 'into', 'the', 'railroad', 'business']\n",
      "IBM Model 1 :p( ['in', 'every', 'work', 'he', 'entered', 'he', 'came', 'across', 'a', 'struggle', 'so', 'now', 'he', 'switched', 'into', 'the', 'railroad', 'business'] | ['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'] ) = 0.0\n",
      "IBM Model 2: p( ['in', 'every', 'work', 'he', 'entered', 'he', 'came', 'across', 'a', 'struggle', 'so', 'now', 'he', 'switched', 'into', 'the', 'railroad', 'business'] | ['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'] ) = 0.0\n",
      "{0: ['in', 'every', 'work', 'he', 'tried', 'he', 'struggled', 'and', 'was', 'working', 'in', 'the', 'railway', 'department', 'now'], 1: ['in', 'every', 'work', 'he', 'entered', 'he', 'came', 'across', 'a', 'struggle', 'so', 'now', 'he', 'switched', 'into', 'the', 'railroad', 'business'], 2: ['in', 'every', 'job', 'he', 'tried', 'he', 'was', 'misfortunate', 'and', 'now', 'he', 'switched', 'to', 'working', 'in', 'the', 'railroad', 'business'], 3: ['he', 'had', 'ruined', 'his', 'prospects', 'in', 'a', 'number', 'of', 'positions', 'and', 'was', 'now', 'serving', 'in', 'the', 'railway', 'department']} ['in', 'every', 'job', 'he', 'tried', 'he', 'was', 'misfortunate', 'and', 'now', 'he', 'switched', 'to', 'working', 'in', 'the', 'railroad', 'business']\n",
      "IBM Model 1 :p( ['in', 'every', 'job', 'he', 'tried', 'he', 'was', 'misfortunate', 'and', 'now', 'he', 'switched', 'to', 'working', 'in', 'the', 'railroad', 'business'] | ['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'] ) = 0.0\n",
      "IBM Model 2: p( ['in', 'every', 'job', 'he', 'tried', 'he', 'was', 'misfortunate', 'and', 'now', 'he', 'switched', 'to', 'working', 'in', 'the', 'railroad', 'business'] | ['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'] ) = 0.0\n",
      "{0: ['in', 'every', 'work', 'he', 'tried', 'he', 'struggled', 'and', 'was', 'working', 'in', 'the', 'railway', 'department', 'now'], 1: ['in', 'every', 'work', 'he', 'entered', 'he', 'came', 'across', 'a', 'struggle', 'so', 'now', 'he', 'switched', 'into', 'the', 'railroad', 'business'], 2: ['in', 'every', 'job', 'he', 'tried', 'he', 'was', 'misfortunate', 'and', 'now', 'he', 'switched', 'to', 'working', 'in', 'the', 'railroad', 'business'], 3: ['he', 'had', 'ruined', 'his', 'prospects', 'in', 'a', 'number', 'of', 'positions', 'and', 'was', 'now', 'serving', 'in', 'the', 'railway', 'department']} ['he', 'had', 'ruined', 'his', 'prospects', 'in', 'a', 'number', 'of', 'positions', 'and', 'was', 'now', 'serving', 'in', 'the', 'railway', 'department']\n",
      "IBM Model 1 :p( ['he', 'had', 'ruined', 'his', 'prospects', 'in', 'a', 'number', 'of', 'positions', 'and', 'was', 'now', 'serving', 'in', 'the', 'railway', 'department'] | ['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'] ) = 0.0\n",
      "IBM Model 2: p( ['he', 'had', 'ruined', 'his', 'prospects', 'in', 'a', 'number', 'of', 'positions', 'and', 'was', 'now', 'serving', 'in', 'the', 'railway', 'department'] | ['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'] ) = 0.0\n",
      "{0: ['Between', 'different', 'trials', 'he', 'would', 'drink', 'his', 'tea', 'smoke', 'his', 'cigarette', 'and', 'talk', 'about', 'some', 'politics', 'daily', 'errands', 'some', 'cardgames', 'and', 'mostly', 'about', 'appointments'], 1: ['in', 'the', 'intervals', 'between', 'the', 'sessions', 'he', 'smoked', 'drank', 'tea', 'chatted', 'a', 'little', 'about', 'politics', 'a', 'little', 'about', 'general', 'topics', 'a', 'little', 'about', 'cards', 'but', 'most', 'of', 'all', 'about', 'official', 'appointments']} ['Between', 'different', 'trials', 'he', 'would', 'drink', 'his', 'tea', 'smoke', 'his', 'cigarette', 'and', 'talk', 'about', 'some', 'politics', 'daily', 'errands', 'some', 'cardgames', 'and', 'mostly', 'about', 'appointments']\n",
      "IBM Model 1 :p( ['Between', 'different', 'trials', 'he', 'would', 'drink', 'his', 'tea', 'smoke', 'his', 'cigarette', 'and', 'talk', 'about', 'some', 'politics', 'daily', 'errands', 'some', 'cardgames', 'and', 'mostly', 'about', 'appointments'] | ['duruşma', 'aralarında', 'çayım', 'içip', 'sigarasını', 'tüttürerek', 'biraz', 'siyasetten', 'biraz', 'günlük', 'işlerden', 'biraz', 'kâğıt', 'oyunlarından', 'daha', 'çok', 'da', 'atamalardan', 'söz', 'açtığı', 'olurdu'] ) = 0.0\n",
      "IBM Model 2: p( ['Between', 'different', 'trials', 'he', 'would', 'drink', 'his', 'tea', 'smoke', 'his', 'cigarette', 'and', 'talk', 'about', 'some', 'politics', 'daily', 'errands', 'some', 'cardgames', 'and', 'mostly', 'about', 'appointments'] | ['duruşma', 'aralarında', 'çayım', 'içip', 'sigarasını', 'tüttürerek', 'biraz', 'siyasetten', 'biraz', 'günlük', 'işlerden', 'biraz', 'kâğıt', 'oyunlarından', 'daha', 'çok', 'da', 'atamalardan', 'söz', 'açtığı', 'olurdu'] ) = 0.0\n",
      "{0: ['Between', 'different', 'trials', 'he', 'would', 'drink', 'his', 'tea', 'smoke', 'his', 'cigarette', 'and', 'talk', 'about', 'some', 'politics', 'daily', 'errands', 'some', 'cardgames', 'and', 'mostly', 'about', 'appointments'], 1: ['in', 'the', 'intervals', 'between', 'the', 'sessions', 'he', 'smoked', 'drank', 'tea', 'chatted', 'a', 'little', 'about', 'politics', 'a', 'little', 'about', 'general', 'topics', 'a', 'little', 'about', 'cards', 'but', 'most', 'of', 'all', 'about', 'official', 'appointments']} ['in', 'the', 'intervals', 'between', 'the', 'sessions', 'he', 'smoked', 'drank', 'tea', 'chatted', 'a', 'little', 'about', 'politics', 'a', 'little', 'about', 'general', 'topics', 'a', 'little', 'about', 'cards', 'but', 'most', 'of', 'all', 'about', 'official', 'appointments']\n",
      "IBM Model 1 :p( ['in', 'the', 'intervals', 'between', 'the', 'sessions', 'he', 'smoked', 'drank', 'tea', 'chatted', 'a', 'little', 'about', 'politics', 'a', 'little', 'about', 'general', 'topics', 'a', 'little', 'about', 'cards', 'but', 'most', 'of', 'all', 'about', 'official', 'appointments'] | ['duruşma', 'aralarında', 'çayım', 'içip', 'sigarasını', 'tüttürerek', 'biraz', 'siyasetten', 'biraz', 'günlük', 'işlerden', 'biraz', 'kâğıt', 'oyunlarından', 'daha', 'çok', 'da', 'atamalardan', 'söz', 'açtığı', 'olurdu'] ) = 0.0\n",
      "IBM Model 2: p( ['in', 'the', 'intervals', 'between', 'the', 'sessions', 'he', 'smoked', 'drank', 'tea', 'chatted', 'a', 'little', 'about', 'politics', 'a', 'little', 'about', 'general', 'topics', 'a', 'little', 'about', 'cards', 'but', 'most', 'of', 'all', 'about', 'official', 'appointments'] | ['duruşma', 'aralarında', 'çayım', 'içip', 'sigarasını', 'tüttürerek', 'biraz', 'siyasetten', 'biraz', 'günlük', 'işlerden', 'biraz', 'kâğıt', 'oyunlarından', 'daha', 'çok', 'da', 'atamalardan', 'söz', 'açtığı', 'olurdu'] ) = 0.0\n"
     ]
    }
   ],
   "source": [
    "####### IBM MODELS #######\n",
    "\n",
    "# read in data\n",
    "nr_used_sentences = 300#1800\n",
    "path = \"./src/Paralel Corpus/\"\n",
    "e, f = read_in_corpus(nr_used_sentences, path)\n",
    "\n",
    "training_split = 0.9\n",
    "e_train, e_test = split_dataset(e, training_split)\n",
    "f_train, f_test = split_dataset(f, training_split)\n",
    "max_steps = 25\n",
    "#TODO remove\n",
    "e_train += [['the' ,'man', 'understood','this','extinguished','his','cigarette','went','to','the','hallway','after','shaking','the','womans','hand']]\n",
    "f_train += [['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı']]\n",
    "\n",
    "# execute IBM Model 1 and 2 each two times (English-Turkish and Turkish-English)\n",
    "t_e2f_ibm1 = EM_IBM_Model_1(e_train, f_train, max_steps)\n",
    "t_e2f, a_e2f = EM_IBM_Model_2(e_train, f_train, t_e2f_ibm1, max_steps)\n",
    "t_f2e_ibm1 = EM_IBM_Model_1(f_train, e_train, max_steps)\n",
    "t_f2e, a_f2e = EM_IBM_Model_2(f_train, e_train, t_f2e_ibm1, max_steps)\n",
    "\n",
    "# testing\n",
    "examples_f = [['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı'],['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'], ['duruşma', 'aralarında', 'çayım', 'içip', 'sigarasını', 'tüttürerek', 'biraz', 'siyasetten', 'biraz', 'günlük', 'işlerden', 'biraz', 'kâğıt', 'oyunlarından', 'daha', 'çok', 'da', 'atamalardan', 'söz', 'açtığı', 'olurdu']]\n",
    "examples_e = [{0: ['the' ,'man', 'understood','this','extinguished','his','cigarette','went','to','the','hallway','after','shaking','the','womans','hand'], 1: ['the' ,'man', 'understood','this','extinguished','his','cigarette','went','to','the','hall','while','shaking','hands','with','the','woman'], 2: ['the' ,'man', 'got','it','and','put','the','cigarette','off','went','to','the','hallway','shaking','the','hand','of','the','woman']},\\\n",
    "            {0:['in','every','work','he','tried','he','struggled','and','was','working','in','the','railway','department','now'],1:['in','every','work','he','entered','he','came','across','a','struggle','so','now','he','switched','into','the','railroad','business'], 2:['in','every','job','he','tried','he','was','misfortunate','and','now','he','switched','to','working','in','the','railroad','business'], 3:['he', 'had', 'ruined', 'his', 'prospects', 'in', 'a', 'number', 'of', 'positions', 'and', 'was', 'now', 'serving', 'in', 'the', 'railway', 'department']},\\\n",
    "            {0:['Between','different','trials','he','would','drink','his','tea','smoke','his','cigarette','and','talk','about','some','politics','daily','errands','some','cardgames','and','mostly','about','appointments'], 1:['in','the', 'intervals', 'between', 'the', 'sessions', 'he', 'smoked', 'drank', 'tea', 'chatted', 'a', 'little', 'about', 'politics','a', 'little', 'about', 'general', 'topics', 'a', 'little' ,'about','cards', 'but', 'most', 'of', 'all', 'about', 'official', 'appointments']}]\n",
    "for i in range(0, len(examples_f)):\n",
    "    f = examples_f[i]\n",
    "    for e in examples_e[i].values():\n",
    "        print(examples_e[i], e)\n",
    "        p1 = prob_e_given_f_1(e, f, 1, t_f2e_ibm1)\n",
    "        print('IBM Model 1 :p(', e, '|', f, ') =', p1)\n",
    "        p2 = prob_e_given_f_2(e, f, 1, t_f2e, a_f2e)\n",
    "        print('IBM Model 2: p(', e, '|', f, ') =', p2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-64e161f24f26>\", line 10, in <module>\n",
      "    for si in range(0, len(f_train)):\n",
      "NameError: name 'f_train' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/lena/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "AttributeError: module has no attribute '__name__'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "####### PHRASE BASED MODEL #######\n",
    "# alignment e:[f]\n",
    "examples_a = [{0: {0:[0], 1:[0], 2:[2], 3:[1], 4:[4], 5:[3], 6:[3], 7:[9], 8:[8], 9:[8], 10:[8], 11:[7], 12:[7], 13:[5], 14:[5],15:[6]}, 1: {0:[0], 1:[0], 2:[2], 3:[1], 4:[4], 5:[3], 6:[3], 7:[9], 8:[8], 9:[8], 10:[8], 11:[7], 12:[7], 13:[6], 14:[5],15:[5],16:[5]}, 2: {0:[0], 1:[0], 2:[2], 3:[1], 4:[4], 5:[4], 6:[3], 7:[3], 8:[4], 9:[9], 10:[8], 11:[8], 12:[8], 13:[7], 14:[6],15:[6],16:[5],17:[5],18:[5]}},\\\n",
    "{0: {0:[2], 1:[1], 2:[2], 3:[0], 4:[0], 5:[3,4,5], 6:[3,4,5], 7:[7], 8:[10], 9:[10], 10:[9], 11:[9], 12:[8], 13:[9], 14:[6]}, 1: {0:[2], 1:[1], 2:[2], 3:[0], 4:[0], 5:[5], 6:[5], 7:[5], 8:[4], 9:[4], 10:[7], 11:[6], 12:[10], 13:[10], 14:[9],15:[9],16:[8],17:[9]}, 2: {0:[2], 1:[1], 2:[2], 3:[0], 4:[0], 5:[3,4,5], 6:[3,4,5], 7:[3,4,5], 8:[7], 9:[6], 10:[10], 11:[10], 12:[10], 13:[10], 14:[9],15:[9],16:[8],17:[9]}, 3: {0:[4], 1:[3,4,5], 2:[3,4,5], 3:[3,4,5], 4:[3,4,5], 5:[2], 6:[1], 7:[1], 8:[1], 9:[2], 10:[7], 11:[10], 12:[6], 13:[10], 14:[9],15:[9],16:[8],17:[9]}},\\\n",
    "{0: {0:[1], 1:[0], 2:[0], 3:[3], 4:[3], 5:[3], 6:[2], 7:[2], 8:[5], 9:[4], 10:[4], 11:[18,19,20], 12:[18,19,20], 13:[6], 14:[7],15:[9],16:[10],17:[11],18:[12,13],19:[14],20:[14,15],21:[17],22:[17]}, 1: {0: [1], 1: [1], 2: [1], 3: [0], 4: [0], 5: [0], 6: [4,5], 7: [4,5], 8: [3], 9: [2], 10: [18,19,20], 11: [6],  12: [6], 13: [7], 14: [7], 15: [8], 16: [8], 17: [10], 18: [9], 19: [10], 20: [11], 21: [11], 22: [13],23:[12,13],24:[16],25:[14,15],26:[14,15],27:[14,15],28:[17],29:[17],30:[17]}}]\n",
    "\n",
    "# use IBM Model 2 for Viterbi alignments & combine them\n",
    "\n",
    "all_a_train = {}\n",
    "for si in range(0, len(f_train)):\n",
    "    e2f = viterbi_alignment(e_train[si], f_train[si], t_e2f, a_e2f)\n",
    "    f2e = viterbi_alignment(f_train[si], e_train[si], t_f2e, a_f2e)\n",
    "    a = combine(f2e, e2f)\n",
    "    all_a_train[si] = a\n",
    "all_a_train[len(f_train)-1] = examples_a[0][0]\n",
    "# extract phrases & estimate phrase translation probabilities\n",
    "\n",
    "max_phrase_len = 5\n",
    "phrase_counts = phrase_extraction(e_train, f_train, all_a_train, max_phrase_len)\n",
    "#print(phrase_counts)\n",
    "# train bigram language model LM\n",
    "unigram_counts, bigram_counts = count_grams(e_train)\n",
    "# testing\n",
    "\n",
    "#examples_f = [['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı'],['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'], ['duruşma', 'aralarında', 'çayım', 'içip', 'sigarasını', 'tüttürerek', 'biraz', 'siyasetten', 'biraz', 'günlük', 'işlerden', 'biraz', 'kâğıt', 'oyunlarından', 'daha', 'çok', 'da', 'atamalardan', 'söz', 'açtığı', 'olurdu']]\n",
    "#examples_e = [{0: ['the' ,'man', 'understood','this','extinguished','his','cigarette','went','to','the','hallway','after','shaking','the','womans','hand'], 1: ['the' ,'man', 'understood','this','extinguished','his','cigarette','went','to','the','hall','while','shaking','hands','with','the','woman'], 2: ['the' ,'man', 'got','it','and','put','the','cigarette','off','went','to','the','hallway','shaking','the','hand','of','the','woman']},\\\n",
    " #           {0:['in','every','work','he','tried','he','struggled','and','was','working','in','the','railway','department','now'],1:['in','every','work','he','entered','he','came','across','a','struggle','so','now','he','switched','into','the','railroad','business'], 2:['in','every','job','he','tried','he','was','misfortunate','and','now','he','switched','to','working','in','the','railroad','business'], 3:['he', 'had', 'ruined', 'his', 'prospects', 'in', 'a', 'number', 'of', 'positions', 'and', 'was', 'now', 'serving', 'in', 'the', 'railway', 'department']},\\\n",
    "  #          {0:['Between','different','trials','he','would','drink','his','tea','smoke','his','cigarette','and','talk','about','some','politics','daily','errands','some','cardgames','and','mostly','about','appointments'], 1:['in','the', 'intervals', 'between', 'the', 'sessions', 'he', 'smoked', 'drank', 'tea', 'chatted', 'a', 'little', 'about', 'politics','a', 'little', 'about', 'general', 'topics', 'a', 'little' ,'about','cards', 'but', 'most', 'of', 'all', 'about', 'official', 'appointments']}]\n",
    "# e_to: (e_from, f_from, f_to)\n",
    "aligned_phrases = [{0: {1:(0,0,0), 2:(2,2,2), 3:(3,1,1), 6:(4,3,4), 10:(7,8,9), 15:(11,5,7)}, 1: {1:(0,0,0), 2:(2,2,2), 3:(3,1,1), 6:(4,3,4), 10:(7,8,9), 16:(11,5,7)}, 2: {1:(0,0,0), 2:(2,2,2), 3:(3,1,1), 8:(4,3,4), 12:(9,8,9), 18:(13,5,7)}}]\n",
    "for sentence in range(0, 1):#len(examples_f)):#TODO for all sentences & not only first after I filled aligned_phrases\n",
    "    f = examples_f[sentence]\n",
    "    for index, e in examples_e[sentence].items():\n",
    "        a = examples_a[sentence][index]\n",
    "        phrases_a = aligned_phrases[sentence][index]\n",
    "        prob = prob_e_given_f(e, f, a, phrase_counts, unigram_counts, bigram_counts, phrases_a)\n",
    "        print('p(', e, '|', f, ') =', prob,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
