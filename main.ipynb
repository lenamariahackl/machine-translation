{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '/home/lena/Desktop/Application Project/src/ibm1.py'\n",
    "%run '/home/lena/Desktop/Application Project/src/ibm2.py'\n",
    "%run '/home/lena/Desktop/Application Project/src/pbmt.py'\n",
    "%run '/home/lena/Desktop/Application Project/src/utils.py'\n",
    "%run '/home/lena/Desktop/Application Project/src/test.py'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cahi̇li̇ye', 'toplumunda', 'i̇nsan'], ['size', 'allahtan', 'bir', 'nur', 've', 'apaçık'], ['bir', 'kitap', 'geldi'], ['kendi', 'izniyle', 'karanlıklardan', 'nura', 'çıkarır'], ['onları', 'dosdoğru', 'yola', 'yöneltipiletir'], ['i̇nsana', 'yaratılış', 'amacını', 'bildiren', 'doğruyu', 'yanlışı', 'gösteren', 've', 'hayatın', 'gerçek', 'yönlerini', 'açıklayan', 'yol', 'göstericimiz', 'kuranı', 'kerimdir'], ['çünkü', 'kuranı', 'insanları', 'yaratan', 'onların', 'tek', 'hakimi', 've', 'tek', 'sahibi', 'olan', 'allah', 'indirmiştir'], ['dolayısıyla', 'insanın', 'bilmediklerini', 'öğrenebilmesi', 've', 'içerisinde', 'bulunduğu', 'cahillikten', 'kurtulup', 'bilinçlenebilmesi', 'de', 'ancak', 'kuranda', 'bildirilen', 'din', 'ahlakını', 'yaşamasıyla', 'mümkündür'], ['bu', 'önemli', 'gerçeği', 'göz', 'ardı', 'ederek', 'din', 'ahlakından', 'uzak', 'yaşayan', 'kimseler', 'ise', 'cahil', 'bir', 'toplum', 'oluştururlar'], ['fakat', 'bu', 'cahillik', 'yaygın', 'olarak', 'kullanılan', 'anlamından', 'tamamen', 'farklıdır'], ['bu', 'kimseler', 'görgü', 'kültür', 'ya', 'da', 'tahsil', 'bakımından', 'kendilerini', 'geliştirmiş', 'kişiler', 'olabilirler', 'ya', 'da', 'bilimin', 'birçok', 'dalında', 'uzmanlaşmış', 'yüzlerce', 'kitap', 'okumuş', 'sayısız', 'buluşta', 'bulunmuş', 've', 'hatta', 'bu', 'birikimleriyle', 'yaşadıkları', 'döneme', 'isimlerini', 'yazdırmış', 'kimseler', 'de', 'olabilirler'], ['ancak', 'bu', 'insanların', 'ne', 'konumları', 'ne', 'birikimleri', 'ne', 'ürettikleri', 'formüller', 'ne', 'de', 'okudukları', 'kitaplar', 'içerisinde', 'bulundukları', 'cehaleti', 'gidermeye', 'yeter'], ['çünkü', 'söz', 'konusu', 'olan', 'cahillik', 'bu', 'kimselerin', 'yaratıcımız', 'olan', 'allahı', 'tanımamaları', 'onun', 'kudretini', 'gereği', 'gibi', 'takdir', 'edememeleri', 'onun', 'kendilerinden', 'neler', 'beklediğini', 'allahın', 'hoşnut', 'olacağı', 'umulan', 'ahlak', 've', 'kişilik', 'yapısının', 'nasıl', 'olması', 'gerektiğini', 'bilmemelerinden', 'kaynaklanan', 'bir', 'cahilliktir'], ['bu', 'köklü', 'cehalet', 'onların', 'yaşam', 'tarzlarından', 'kişilik', 'yapılarına', 'kadar', 'hayatlarının', 'her', 'anında', 'olumsuz', 'etkilerini', 'gösterir'], ['bu', 'cahillikten', 'kurtulmanın', 'tek', 've', 'kesin', 'çözümü', 'ise', 'allahın', 'insanlara', 'dünya', 've', 'ahiret', 'hayatına', 'ait', 'tüm', 'sırları', 've', 'gerçekleri', 'bildirdiği', 've', 'bilmediklerini', 'öğrettiği', 'kurana', 'yönelmeleridir'], ['aksinde', 'ise', 'tek', 'bir', 'kaynak', 'tek', 'bir', 'doğru', 've', 'tek', 'bir', 'din', 'kavramı', 'olmayacağı', 'için', 'ortaya', 'binlerce', 'ayrı', 'inanç', 've', 'karakter', 'çıkar'], ['bu', 'farklı', 'karakterleri', 'taşıyan', 'insanların', 'her', 'birinin', 'yaşama', 'amaçları', 'idealleri', 'ahlak', 'anlayışları', 'doğruları', 'yanlışları', 've', 'yaşam', 'tarzları', 'da', 'birbirinden', 'ayrıdır', 'bu', 'yapılar', 'birbirlerine', 'kıyasla', 'o', 'kadar', 'büyük', 'zıtlıklar', 'içerir', 'ki', 'bu', 'kimselerin', 'birarada', 'uyumlu', 'bir', 'şekilde', 'yaşayabilmeleri', 'çoğu', 'zaman', 'mümkün', 'olmaz'], ['herkes', 'kendi', 'inancının', 've', 'kendi', 'yaşam', 'tarzının', 'doğruluğunu', 'savunur', 've', 'başkalarınınkini', 'eleştirir'], ['birbirlerini', 'beğenmedikleri', 've', 'pek', 'çok', 'noktada', 'çeliştikleri', 'için', 'de', 'zor', 'bir', 'hayat', 'yaşarlar', 'bu', 'insanlar', 'için', 'tek', 'çözüm', 'ise', 'başta', 'da', 'belirtildiği', 'gibi', 'din', 'ahlakının', 'sunduğu', 'güzel', 'hayatı', 'yaşamaktır'], ['çünkü', 'insanı', 'yaratan', 'allah', 'yine', 'onun', 'en', 'ideal', 'hayatı', 'yaşayabileceği', 've', 'herşeyden', 'en', 'çok', 'zevki', 'alabileceği', 'sistemi', 'kuranda', 'bildirmiştir'], ['i̇şte', 'bu', 'kitabın', 'amacı', 'da', 'cahiliye', 'toplumunun', 'ürettiği', 'yaşam', 'tarzlarından', 've', 'karakterlerden', 'belli', 'başlı', 'örnekleri', 'inceleyerek', 'bu', 'sistemin', 'tüm', 'şekillerinin', 'kesin', 'olarak', 'açmazda', 'olduğunu', 'ortaya', 'koymaktır'], ['ayrıca', 'cahiliye', 'toplumunu', 'oluşturan', 'insanların', 'yaşadıkları', 'klasik', 'karakterlerle', 'aradıkları', 'huzur', 've', 'mutluluğa', 'hiçbir', 'şekilde', 'ulaşamadıklarını', 'göstermektir'], ['bunun', 'yanı', 'sıra', 'kitapta', 'kuranda', 'bildirilen', 'mümin', 'karakterinin', 'cahiliye', 'toplumunun', 'ortaya', 'çıkarttığı', 'binlerce', 'karakterin', 'hepsinin', 'üstünde', 'olduğu', 'tarif', 'edilecek', 've', 'yine', 'müminin', 'yaşadığı', 'hayatın', 'cahiliye', 'sistemlerindekinin', 'tam', 'aksine', 'ne', 'denli', 'mükemmel', 'olduğu', 'ortaya', 'koyulacaktır'], ['genel', 'yapisi'], ['cahiliye', 'kavramı', 'cahil', 'kelimesinden', 'türeyen', 've', 'kuranda', 'kullanılan', 'anlamıyla', 'allahı', 'gereği', 'gibi', 'tanımayan', 'onun', 'sonsuz', 'gücünü', 've', 'sıfatlarını', 'gereği', 'gibi', 'takdir', 'edemeyen', 'i̇slam', 'dininde', 'var', 'olan', 'doğrulardan', 'insanlara', 'sunduğu', 'üstün', 'ahlak', 've', 'karakter', 'yapısından', 'manevi', 'değerlerden', 'habersiz', 'olan', 'toplumları', 'tanımlar'], ['din', 'ahlakının', 'gerçek', 'anlamda', 'yaşanmadığı', 'her', 'topluluk', 'cahiliye', 'toplumu', 'olarak', 'nitelendirilebilir'], ['bu', 'tarz', 'topluluklar', 'ilk', 'bakışta', 'birbirlerinden', 'tamamen', 'farklı', 've', 'zıt', 'yapılar', 'sergileyebilirler', 'bu', 'gibi', 'kişilerin', 'giyim', 'tarzları', 'alışkanlıkları', 'zevkleri', 've', 'konuşma', 'üslupları', 'kendilerine', 'has', 'olabilir'], ['ancak', 'temel', 'felsefeleri', 've', 'inançları', 'ortaktır'], ['bu', 'toplulukların', 'her', 'biri', 'allahın', 'dinini', 'görmezlikten', 'gelen', 've', 'kendilerini', 'yaratanın', 'allah', 'olduğunu', 'anladıkları', 'halde', 'onun', 'belirlediği', 'şekilde', 'yaşamayan', 'insanlardan', 'oluşur'], ['bu', 'insanlar', 'allahın', 'dinini', 'unutup', 'yerine', 'kendi', 'batıl', 'dinlerini', 'oluşturmuşlardır'], ['bu', 'batıl', 'dinler', 'temellerini', 'allah', 'sevgisi', 'yerine', 'dünya', 'sevgisi', 'üzerine', 'kurmuşlardır'], ['allahın', 'rızasını', 'kazanmak', 'yerine', 'insanların', 'beğenilerini', 've', 'takdirlerini', 'kazanmaya', 'çabalarlar'], ['allaha', 'şükretmek', 've', 'yalnızca', 'ondan', 'yardım', 'dilemek', 'yerine', 'insanlara', 'minnet', 'duyup', 'onlara', 'bağımlı', 'tavırlar', 'geliştirirler'], ['yine', 'tüm', 'gücün', 'tek', 'sahibinin', 'allah', 'olduğunu', 'unutarak', 'yalnızca', 'ondan', 'korkmak', 'yerine', 'insanlardan', 've', 'onların', 'koydukları', 'kurallardan', 'korkar', 'olmuşlardır'], ['ancak', 'cahiliye', 'toplumu', 'denince', 'akla', 'sadece', 'kuran', 'ahlakından', 'tamamen', 'habersiz', 'insanlar', 'gelmemelidir', 'bu', 'insanların', 'bir', 'kısmı', 'hak', 'dini', 'çok', 'yakından', 'tanıdıkları', 'halde', 'yine', 'de', 'içerisine', 'düştükleri', 'bu', 'cehaletten', 'çıkamazlar'], ['bu', 'kimseler', 'allahın', 'emrettiği', 'bazı', 'ibadetleri', 'uyguladıkları', 'halde', 'kuran', 'ahlakını', 've', 'mümin', 'karakterini', 'yaşamaya', 'yanaşmazlar'], ['bunun', 'nedenleri', 'ise', 'bu', 'kimselerin', 'temelde', 'kalplerini', 'allaha', 'bağlamamış', 'olmaları', 've', 'bilinçaltlarında', 'ahiretten', 'kuşku', 'içinde', 'olmalarıdır'], ['dünyaya', 'duydukları', 'sevgi', 'kuran', 'dışı', 'karakterler', 'geliştirmelerine', 've', 'din', 'ahlakını', 'tanıdıkları', 'halde', 'cahiliye', 'toplumunun', 'cehaletinden', 'kurtulamamalarına', 'sebep', 'olur'], ['dünyanın', 'dört', 'bir', 'yanında', 'birbirinden', 'tamamen', 'bağımsız', 've', 'birbirlerine', 'tamamen', 'zıt', 'bakış', 'açıları', 'içerisinde', 'yaşayan', 'bu', 'topluluklarda', 'ortak', 'bir', 'yaşam', 've', 'bir', 'inanç', 'şekli', 'gözlenmektedir'], ['bu', 'nedenle', 'cahiliye', 'toplumunda', 'yaşanan', 'insan', 'karakterlerine', 'değinmeden', 'önce', 'bu', 'farklı', 'karakterlerin', 'altında', 'yatan', 'ortak', 'felsefeyi', 've', 'ortak', 'inançları', 'incelemekte', 'fayda', 'vardır']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"# Testing\\n# only works for test test_set, not for real data\\ncorrect1 = 0\\ncorrect2 = 0\\nbool_test = [True, True, True, False, False, False] #correct prob values around[1, 0.7, 0.9, 0.1, 0.01, 0]\\nfor i in range(0, len(f_test)):\\n    f = f_test[i]\\n    e = e_test[i]\\n    p1 = prob_e_given_f_1(e, f, 1, t_e2f_ibm1)\\n    if (p1 > 0.5) == bool_test[i]: correct1 += 1\\n    print('p_IBM1(', e, '|', f, ') =', p1)\\n    p2 = prob_e_given_f_2(e, f, 1, t_e2f, a_e2f)\\n    if (p2 > 0.5) == bool_test[i]: correct2 += 1\\n    print('p_IBM2(', e, '|', f, ') =', p2)\\nprint('IBM Model 1 :', int(100*(correct1/len(f_test))),'% correct')\\nprint('IBM Model 2 :', int(100*(correct2/len(f_test))),'% correct')\\n\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "TEST = False \n",
    "nr_used_sentences = 50 #1800 for 1model,25steps  # of 688670 lines\n",
    "path = \"./src/Paralel Corpus/\"\n",
    "e, f = read_in_corpus(nr_used_sentences, path)\n",
    "\n",
    "training_split = 0.9\n",
    "e_train, e_test = split_dataset(e, training_split)\n",
    "f_train, f_test = split_dataset(f, training_split)\n",
    "if TEST:\n",
    "    # we don't use real data but instead [['house','the','the'],['the','the','book'],['a','book']] etc\n",
    "    e_train, f_train, all_alignments_train, e_test, f_test, all_alignments_test = initialize_test_sets()\n",
    "\n",
    "max_steps = 75#25\n",
    "\n",
    "t_e2f_ibm1 = EM_IBM_Model_1(e_train, f_train, max_steps, )\n",
    "t_e2f, a_e2f = EM_IBM_Model_2(e_train, f_train, t_e2f_ibm1, max_steps)\n",
    "t_f2e_ibm1 = EM_IBM_Model_1(f_train, e_train, max_steps)\n",
    "t_f2e, a_f2e = EM_IBM_Model_2(f_train, e_train, t_f2e_ibm1, max_steps)\n",
    "\n",
    "if TEST:\n",
    "    # alignment probabilities a gives different results than implementation in the nltk library\n",
    "    compare_ibm_1_nltk(t_e2f_ibm1, max_steps, e_train, f_train)\n",
    "    compare_ibm_2_nltk(t_e2f, max_steps, a_e2f, e_train, f_train)\n",
    "    compare_ibm_2_nltk(t_f2e, max_steps, a_f2e, f_train, e_train)\n",
    "    \n",
    "    # compare a's train() and EM_IBM_Model_2() > 99% same a\n",
    "    #compare_a_ibm_2_train(t_e2f, max_steps, a_e2f, e_train, f_train)\n",
    "    #compare_a_ibm_2_train(t_f2e, max_steps, a_f2e, f_train, e_train)\n",
    "\n",
    "    # calculate sum of a over all words f: should be 1 \n",
    "    #test_sum_a_is_one(a_e2f, f_train)\n",
    "    #test_sum_a_is_one(a_f2e, e_train)\n",
    "    #compare_a_nltk_train(t_e2f_ibm1, max_steps, e_train, f_train)\n",
    "\n",
    "    \n",
    "\"\"\"# Testing\n",
    "# only works for test test_set, not for real data\n",
    "correct1 = 0\n",
    "correct2 = 0\n",
    "bool_test = [True, True, True, False, False, False] #correct prob values around[1, 0.7, 0.9, 0.1, 0.01, 0]\n",
    "for i in range(0, len(f_test)):\n",
    "    f = f_test[i]\n",
    "    e = e_test[i]\n",
    "    p1 = prob_e_given_f_1(e, f, 1, t_e2f_ibm1)\n",
    "    if (p1 > 0.5) == bool_test[i]: correct1 += 1\n",
    "    print('p_IBM1(', e, '|', f, ') =', p1)\n",
    "    p2 = prob_e_given_f_2(e, f, 1, t_e2f, a_e2f)\n",
    "    if (p2 > 0.5) == bool_test[i]: correct2 += 1\n",
    "    print('p_IBM2(', e, '|', f, ') =', p2)\n",
    "print('IBM Model 1 :', int(100*(correct1/len(f_test))),'% correct')\n",
    "print('IBM Model 2 :', int(100*(correct2/len(f_test))),'% correct')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrase - based MT\n",
    "#Input: sets of sentences e and f, t- and a-table in both directions\n",
    "#Output: alignments for sentences in sets\n",
    "def word_alignment(e, f, t_e2f, a_e2f, t_f2e, a_f2e):\n",
    "    all_a = {}\n",
    "    for si in range(0, len(f)):\n",
    "        e2f = viterbi_alignment(e[si], f[si], t_e2f, a_e2f)\n",
    "        f2e = viterbi_alignment(f[si], e[si], t_f2e, a_f2e)\n",
    "        a = combine(f2e, e2f)\n",
    "        if (a == all_alignments_train[si]): print('Right alignment :)\\n')\n",
    "        else: \n",
    "            print(e[si],f[si],'\\ne2f    ',e2f,'\\nf2e    ',f2e,'\\ncombine', a)\n",
    "            print('Returned wrong alignment',a,'\\nRight alignment would be',all_alignments_train[si],'\\n')\n",
    "        all_a[si] = a\n",
    "    return all_a\n",
    "\n",
    "# IBM Model 2 for word alignment\n",
    "all_a_train = word_alignment(e_train, f_train, t_e2f, a_e2f, t_f2e, a_f2e)\n",
    "#all_a_test = word_alignment(e_test, f_test, t_e2f, a_e2f, t_f2e, a_f2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HEREEEEE\n",
    "\"\"\"\n",
    "{['house']:{['Haus']:1}, (['house', 'the'], ['das', 'Haus']), (['house', 'the', 'the'], ['das', 'Haus']), (['the'], ['das']), (['the', 'the'], ['das']), (['the'], ['das', 'Buch']), (['the', 'the'], ['das', 'Buch']), (['the', 'the', 'book'], ['das', 'Buch']), (['a'], ['ein']), (['a', 'book'], ['ein', 'Buch']), (['book'], ['Buch']), (['house'], ['Haus'])]\n",
    "\"\"\"\n",
    "e_train = [['michael','assumes','that','he','will','stay','in','the','house']]\n",
    "f_train = [['michael','geht','davon','aus',',','dass','er','im','haus','bleibt']]\n",
    "all_a_train = {0:{0:[0],1:[1,2,3],2:[5],3:[6],4:[9],5:[9],6:[7],7:[7],8:[8]}}\n",
    "# all_a[a][b] alignment for b word in e for sentence a\n",
    "#\"\"\"\n",
    "counts = phrase_extraction(e_train, f_train, all_a_train, 3)\n",
    "#counts = phrase_extraction(e_test, f_test, all_a_test, 3)\n",
    "print('counts:',counts,'\\n')\n",
    "\n",
    "#phrase translation table\n",
    "print('PT_prob([\\'house\\'], [\\'Haus\\']) =', PT_prob(['house'], ['Haus'], counts))\n",
    "print('PT_prob([\\'the\\',\\'house\\'], [\\'das\\',\\'Haus\\']) =', PT_prob(['the','house'],['das','Haus'],counts),'\\n')\n",
    "\n",
    "#bigram language model\n",
    "unigram_counts, bigram_counts = count_grams(e_test)\n",
    "#print('unigram_counts',unigram_counts,'\\n bigram_counts', bigram_counts,'\\n')\n",
    "\n",
    "prev = 'book'\n",
    "cur = 'a'\n",
    "print('P(',cur,'|',prev,') should be high',LM_prob(prev, cur, unigram_counts, bigram_counts))\n",
    "cur = 'house'\n",
    "print('P(',cur,'|',prev,') should be low', LM_prob(prev, cur, unigram_counts, bigram_counts))\n",
    "\n",
    "# TODO phrase-based statistical machine translation model\n",
    "# • the phrase translation table φ(f|e);\n",
    "# • the reordering model d;\n",
    "# • the language model pLM(e).\n",
    "# e_best = argmax_e prod_i φ(f|e) * d(start_i - end_i_min_1 - 1) * prod_i PLM(e_i|e_i_min_1)\n",
    "for sentence in range(0, len(all_alignments_test)):\n",
    "    f = f_test[sentence]\n",
    "    e = e_test[sentence]\n",
    "    alignment = all_alignments_test[sentence]\n",
    "    prob = prob_e_given_f(e, f, alignment, counts, unigram_counts, bigram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO unaligned cases!\n",
    "#model null alignments, some word doesnt have a word to align to \n",
    "#> just align it with the highest probable one\n",
    "\n",
    "#debug ibm 2\n",
    "#IBM Model 2: How to calculate a correctly?\n",
    "#my a is 1 when it should be low :(\n",
    "#implementation exactly like in book\n",
    "#eg sum is supposed to always be 1\n",
    "#use ibm model 2 in slides\n",
    "#compare subresults if they are right, count, stotal etc\n",
    "#look into indexing, starting 0 / 1?\n",
    "\n",
    "# TODO translation probability is not working for phrases containing several words\n",
    "#p(e|f) for IBM Model 2: Gives result 4 should be 1?\n",
    "#is sum wrong maybe?\n",
    "#> compare with other implementations\n",
    "\n",
    "#calculating p(e|f) phrase based model\n",
    "\n",
    "#decoding > example target sentences - do we even need the test set?\n",
    "#&gen alignments or manual?\n",
    "\n",
    "#TODO save t, a in files & load them?\n",
    "\n",
    "#structure code more? classes ML model, so it's intuitive to execute\n",
    "\n",
    "#remove special chars preprocessing\n",
    "#Application: Preprocessing convert Turkish characters!\n",
    "#Remove non-ASCII characters\n",
    "#lowercase\n",
    "#multi-character whitespaces to a single whitespace character\n",
    "#Remove URLs, numbers, leading and trailing whitespaces\n",
    "\n",
    "#efficient n-gram with trie\n",
    "#only store ngrams above a certain count threshold eg 4 saving 90%\n",
    "# save a significant amount of memory if we only store terms with some minimum count.\n",
    "\n",
    "#calc how long stuff takes\n",
    "#look into efficiency issues, use hashing?\n",
    "# TODO For the estimation of the phrase translation probabilities, not all\n",
    "# phrase pairs have to be loaded into memory. It is possible to efficiently\n",
    "# estimate the probability distribution by storing and sorting the extracted\n",
    "# phrases on disk. Similarly, when using the translation table for the translation of a single sentence, only a small fraction of it is needed and may\n",
    "# be loaded on demand.\n",
    "# think about saving stuff in file\n",
    "# • Phrase translation table typically bigger than corpus\n",
    "# ... even with limits on phrase lengths (e.g., max 7 words)\n",
    "# → Too big to store in memory?\n",
    "# • Solution for training\n",
    "# – extract to disk, sort, construct for one source phrase at a time\n",
    "# • Solutions for decoding\n",
    "# – on-disk data structures with index for quick look-ups\n",
    "# – suffix arrays to create phrase pairs on demand\n",
    "# TODO use numpy for everything\n",
    "# maybe other data structure ['the','house']:[['das','Haus'],['ein','Haus']]\n",
    "# faster sometimes but slower if translation in other direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### IBM MODELS #######\n",
    "\n",
    "# read in data\n",
    "nr_used_sentences = 10000#00\n",
    "path = \"./src/Paralel Corpus/\"\n",
    "e, f = read_in_corpus(nr_used_sentences, path)\n",
    "\n",
    "training_split = 1#0.9\n",
    "e_train, e_test = split_dataset(e, training_split)\n",
    "f_train, f_test = split_dataset(f, training_split)\n",
    "max_steps = 30\n",
    "\n",
    "#TODO remove\n",
    "e_train += [['the' ,'man', 'understood','this','extinguished','his','cigarette','went','to','the','hallway','after','shaking','the','womans','hand']]\n",
    "f_train += [['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı']]\n",
    "\n",
    "# execute IBM Model 1 and 2 each two times (English-Turkish and Turkish-English)\n",
    "t_e2f_ibm1 = EM_IBM_Model_1(e_train, f_train, max_steps, './models/t_e2f_ibm1.pkl')\n",
    "t_e2f, a_e2f = EM_IBM_Model_2(e_train, f_train, t_e2f_ibm1, max_steps, './models/t_e2f_ibm2.pkl', './models/a_e2f_ibm2.pkl')\n",
    "t_f2e_ibm1 = EM_IBM_Model_1(f_train, e_train, max_steps,'./models/t_f2e_ibm1.pkl')\n",
    "t_f2e, a_f2e = EM_IBM_Model_2(f_train, e_train, t_f2e_ibm1, max_steps, './models/t_f2e_ibm2.pkl', './models/a_f2e_ibm2.pkl')\n",
    "\n",
    "# testing\n",
    "examples_f = [['adam', 'bunu', 'anladı', 'sigarasını', 'söndürdü', 'kadının', 'elini', 'sıkarak', 'hole', 'çıktı'],['girdiği', 'bütün', 'işlerde', 'bir', 'terslikle', 'karşılaşmış', 'şimdi', 'de', 'demiryolu', 'işletmesine', 'geçmişti'], ['duruşma', 'aralarında', 'çayım', 'içip', 'sigarasını', 'tüttürerek', 'biraz', 'siyasetten', 'biraz', 'günlük', 'işlerden', 'biraz', 'kâğıt', 'oyunlarından', 'daha', 'çok', 'da', 'atamalardan', 'söz', 'açtığı', 'olurdu']]\n",
    "examples_e = [{0: ['the' ,'man', 'understood','this','extinguished','his','cigarette','went','to','the','hallway','after','shaking','the','womans','hand'], 1: ['the' ,'man', 'understood','this','extinguished','his','cigarette','went','to','the','hall','while','shaking','hands','with','the','woman'], 2: ['the' ,'man', 'got','it','and','put','the','cigarette','off','went','to','the','hallway','shaking','the','hand','of','the','woman']},\\\n",
    "            {0:['in','every','work','he','tried','he','struggled','and','was','working','in','the','railway','department','now'],1:['in','every','work','he','entered','he','came','across','a','struggle','so','now','he','switched','into','the','railroad','business'], 2:['in','every','job','he','tried','he','was','misfortunate','and','now','he','switched','to','working','in','the','railroad','business'], 3:['he', 'had', 'ruined', 'his', 'prospects', 'in', 'a', 'number', 'of', 'positions', 'and', 'was', 'now', 'serving', 'in', 'the', 'railway', 'department']},\\\n",
    "            {0:['between','different','trials','he','would','drink','his','tea','smoke','his','cigarette','and','talk','about','some','politics','daily','errands','some','cardgames','and','mostly','about','appointments'], 1:['in','the', 'intervals', 'between', 'the', 'sessions', 'he', 'smoked', 'drank', 'tea', 'chatted', 'a', 'little', 'about', 'politics','a', 'little', 'about', 'general', 'topics', 'a', 'little' ,'about','cards', 'but', 'most', 'of', 'all', 'about', 'official', 'appointments']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5046\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'examples_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d99a0db6b9e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_e2f_ibm2_10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexamples_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbest_e_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'examples_f' is not defined"
     ]
    }
   ],
   "source": [
    "t_e2f_ibm1_10000 = load_table('./models/t_e2f_ibm1_10000.pkl')\n",
    "a_e2f_ibm2_10000 = load_table('./models/a_e2f_ibm2_10000.pkl')\n",
    "t_e2f_ibm2_10000 = load_table('./models/t_e2f_ibm2_10000.pkl')\n",
    "\n",
    "for i in range(0, len(examples_f)):\n",
    "    f = examples_f[i]\n",
    "    best_e_1 = ''\n",
    "    max_prob_1 = 0.0\n",
    "    best_e_2 = ''\n",
    "    max_prob_2 = 0.0\n",
    "    for e in examples_e[i].values():\n",
    "        p1 = prob_e_given_f_1(e, f, 1e19, t_e2f_ibm1)\n",
    "        #print('IBM Model 1 :p(', e, '|', f, ') =', p1)\n",
    "        p2 = prob_e_given_f_2(e, f, 1e12, t_e2f, a_e2f)\n",
    "        #print('IBM Model 2: p(', e, '|', f, ') =', p2)\n",
    "        if p1 >= max_prob_1:\n",
    "            max_prob_1 = p1\n",
    "            best_e_1 = e\n",
    "        if p2 >= max_prob_2:\n",
    "            max_prob_2 = p2\n",
    "            best_e_2 = e\n",
    "    print('\\x1b[1;1m'+'Best translation for \\n\"',' '.join(f),'\"'+'\\x1b[0m')\n",
    "    print('according to IBM Model 1 with P(e|f)',max_prob_1,':\\n\"',' '.join(best_e_1),'\"')\n",
    "    print('according to IBM Model 2 with P(e|f)',max_prob_2,':\\n\"',' '.join(best_e_2),'\"\\n')\n",
    "#0.24423984532665258\n",
    "#0.6721854537670273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_grams\n",
      "calculate PT_prob for ['the', 'man'] ['adam'] = 1e-12\n",
      "tutu False ['the', 'man'] ['adam']\n",
      "d( 0 )= 1.0\n",
      "calculate PT_prob for ['understood'] ['anladı'] = 1e-12\n",
      "tutu True ['understood'] ['anladı']\n",
      "{\"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen', 'larvalardan']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen', 'larvalardan', 'çıkıyorlardı']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen', 'larvalardan']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen', 'larvalardan', 'çıkıyorlardı']\": 1}\n",
      "d( 1 )= 0.5\n",
      "calculate PT_prob for ['this'] ['bunu'] = 1e-12\n",
      "tutu True ['this'] ['bunu']\n",
      "{\"['kalplerini']\": 1, \"['cahiliye']\": 1, \"['aldatır']\": 1, \"['de']\": 8, \"['kaybedeceklerdir']\": 1, \"['kaybedeceklerdir', '']\": 1, \"['metadan']\": 1, \"['bir', 'metadan']\": 1, \"['ettikleri']\": 1, \"['ettikleri', 've']\": 1, \"['hayat']\": 1, \"['hayat', 'yaşamalarından']\": 1, \"['hayat', 'yaşamalarından', 'kaynaklanmaz']\": 1, \"['bir', 'hayat']\": 1, \"['bir', 'hayat', 'yaşamalarından']\": 1, \"['bir', 'hayat', 'yaşamalarından', 'kaynaklanmaz']\": 1, \"['hayatını']\": 1, \"['hayatını', 'onun']\": 1, \"['mutlaka']\": 1, \"['mutlaka', 'yaşamak']\": 1, \"['çok', 'önemli', 'bir', 'konudur']\": 1, \"['duygusal']\": 1, \"['yapı']\": 1, \"['yapı', 'başta']\": 1, \"['yapı', 'başta', 'kadınların']\": 1, \"['alışkanlıkları']\": 1, \"['alışkanlıkları', 'tartışmacı']\": 1, \"['alışkanlıkları', 'tartışmacı', 'bir']\": 1, \"['söylenme', 'alışkanlıkları']\": 1, \"['söylenme', 'alışkanlıkları', 'tartışmacı']\": 1, \"['söylenme', 'alışkanlıkları', 'tartışmacı', 'bir']\": 1, \"['beğendiği', 'şekilde', 'bir', 'hayat']\": 1, \"['allahın', 'beğendiği', 'şekilde', 'bir', 'hayat']\": 1, \"['oysa']\": 1, \"['bir']\": 1, \"['kesin', 'bir']\": 1, \"['da']\": 1, \"['da', 'sıkıntılı']\": 1, \"['da', 'sıkıntılı', 'bir']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale', 'getirmekten']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale', 'getirmekten', 'başka']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale', 'getirmekten', 'başka', 'bir']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale', 'getirmekten', 'başka', 'bir', 'işe']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale', 'getirmekten', 'başka', 'bir', 'işe', 'yaramaz']\": 1, \"['nedenle', 'de']\": 1, \"['kuran']\": 1, \"['nedenle', 'de', 'mutlaka']\": 1, \"['nedenle', 'de', 'mutlaka', 'açmazdadırlar']\": 1, \"['olmasa']\": 1, \"['tanımı', 'olmasa']\": 1, \"['cahiliye', 'erkeklerinin']\": 1, \"['gerçek']\": 1, \"['vardır']\": 1, \"['vardır', 'bu']\": 1, \"['etme']\": 1, \"['bazen']\": 1, \"['de', 'sürekli']\": 1, \"['bütün']\": 1, \"['hayatındaki', 'bütün']\": 1, \"['dünya', 'hayatındaki', 'bütün']\": 1, \"['onların', 'dünya', 'hayatındaki', 'bütün']\": 1, \"['karakteri']\": 1, \"['karakteri', 'aynı']\": 1, \"['temizlikçilere']\": 1, \"['temizlikçilere', 'ya']\": 1, \"['temizlikçilere', 'ya', 'da']\": 1, \"['temizlikçilere', 'ya', 'da', 'odacılara']\": 1, \"['i̇şte']\": 1, \"['girdiği']\": 1, \"['girdiği', 'andan']\": 1, \"['asla']\": 1, \"['asla', 'ödün']\": 1, \"['asla', 'ödün', 'vermemelerinden']\": 1, \"['yerleri']\": 1, \"['yerleri', 'yoktur']\": 1, \"['mesleğinden']\": 1, \"['dünya']\": 2, \"['ve']\": 1, \"['zengin']\": 1, \"['zengin', 'çevrelerde']\": 1, \"['itibaren', 'zengin']\": 1, \"['itibaren', 'zengin', 'çevrelerde']\": 1, \"['yaşlardan', 'itibaren', 'zengin']\": 1, \"['yaşlardan', 'itibaren', 'zengin', 'çevrelerde']\": 1, \"['bu']\": 1, \"['bu', 'ahlakı']\": 1, \"['alıştıkları', 'bu']\": 1, \"['alıştıkları', 'bu', 'ahlakı']\": 1, \"['artık', 'alıştıkları', 'bu']\": 1, \"['artık', 'alıştıkları', 'bu', 'ahlakı']\": 1, \"['nedenle', 'rahatlık']\": 1, \"['nedenle', 'rahatlık', 'onu']\": 1, \"['dünya', 'hayatı']\": 1, \"['oysa', 'dünya', 'hayatı']\": 1, \"['için']\": 1, \"['kuranın']\": 1, \"['şöyle']\": 1, \"['anında']\": 1, \"['her', 'anında']\": 1, \"['hayatının', 'her', 'anında']\": 1, \"['imtihan', 'hayatının', 'her', 'anında']\": 1, \"['sığınmaya']\": 1, \"['allaha', 'sığınmaya']\": 1, \"['ve', 'allaha', 'sığınmaya']\": 1, \"['kolaydır']\": 1, \"['bu', 'propaganda', 'gerçeği']\": 1, \"['bu', 'propaganda', 'gerçeği', 'gizleyememektedir']\": 1, \"['ancak', 'bu', 'propaganda', 'gerçeği']\": 1, \"['ancak', 'bu', 'propaganda', 'gerçeği', 'gizleyememektedir']\": 1, \"['çıkıyordu']\": 1, \"['karşı', 'çıkıyordu']\": 1, \"['gerçeğine', 'karşı', 'çıkıyordu']\": 1, \"['hayatın']\": 1, \"['hayatın', 'kendiliğinden']\": 1, \"['ise', 'hayatın']\": 1, \"['ise', 'hayatın', 'kendiliğinden']\": 1, \"['amacı', 'yaratılışı', 'reddetmek']\": 1, \"['amacı', 'yaratılışı', 'reddetmek', 'olan']\": 1, \"['amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim']\": 1, \"['amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim', 'teorisini']\": 1, \"['temel', 'amacı', 'yaratılışı', 'reddetmek']\": 1, \"['temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan']\": 1, \"['temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim']\": 1, \"['temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim', 'teorisini']\": 1, \"['en', 'temel', 'amacı', 'yaratılışı', 'reddetmek']\": 1, \"['en', 'temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan']\": 1, \"['en', 'temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim']\": 1, \"['en', 'temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim', 'teorisini']\": 1, \"['geyikleri']\": 1, \"['mekanizma', 'geyikleri']\": 1, \"['tam']\": 1, \"['tam', 'aksidir']\": 1, \"['öngörülerinin', 'tam']\": 1, \"['öngörülerinin', 'tam', 'aksidir']\": 1, \"['ancak', 'siz', 'bu', 'zifiri', 'karanlıkta', 'ışıklı', 'pırıl', 'pırıl', 'bir']\": 1, \"['ancak', 'siz', 'bu', 'zifiri', 'karanlıkta', 'ışıklı', 'pırıl', 'pırıl', 'bir', 'dünyayı']\": 1, \"['ancak', 'siz', 'bu', 'zifiri', 'karanlıkta', 'ışıklı', 'pırıl', 'pırıl', 'bir', 'dünyayı', 'seyretmektesiniz']\": 1, \"['kadar']\": 1, \"['yerin']\": 1, \"['yerin', 'iki']\": 1, \"['ayırttığı', 'yerin']\": 1, \"['ayırttığı', 'yerin', 'iki']\": 1, \"['geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki']\": 1, \"['geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki', 'en']\": 1, \"['geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki', 'en', 'zor']\": 1, \"['yılında', 'geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki']\": 1, \"['yılında', 'geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki', 'en']\": 1, \"['yılında', 'geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki', 'en', 'zor']\": 1, \"['gönül', 'eğlendirici', 'değilse']\": 1, \"['gönül', 'eğlendirici', 'değilse', 'bile']\": 1, \"['gönül', 'eğlendirici', 'değilse', 'bile', 'can']\": 1, \"['gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı']\": 1, \"['gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı', 'da']\": 1, \"['gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı', 'da', 'değildi']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse', 'bile']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse', 'bile', 'can']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı', 'da']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı', 'da', 'değildi']\": 1}\n",
      "d( -2 )= 0.25\n",
      "calculate PT_prob for ['extinguished', 'his', 'cigarette'] ['sigarasını', 'söndürdü'] = 1e-12\n",
      "tutu False ['extinguished', 'his', 'cigarette'] ['sigarasını', 'söndürdü']\n",
      "d( 1 )= 0.5\n",
      "calculate PT_prob for ['went', 'to', 'the', 'hallway'] ['hole', 'çıktı'] = 1e-12\n",
      "tutu False ['went', 'to', 'the', 'hallway'] ['hole', 'çıktı']\n",
      "d( 3 )= 0.125\n",
      "calculate PT_prob for ['after', 'shaking', 'the', 'womans', 'hand'] ['kadının', 'elini', 'sıkarak'] = 1e-12\n",
      "tutu False ['after', 'shaking', 'the', 'womans', 'hand'] ['kadının', 'elini', 'sıkarak']\n",
      "d( -5 )= 0.03125\n",
      "LM_prob( the | START )= 0.0252014652014652\n",
      "LM_prob( man | the )= 0.00041626196753156655\n",
      "LM_prob( understood | man )= 0.0001968503937007874\n",
      "LM_prob( this | understood )= 0.00019876764062810574\n",
      "LM_prob( extinguished | this )= 0.00018375597206909226\n",
      "LM_prob( his | extinguished )= 0.0001990049751243781\n",
      "LM_prob( cigarette | his )= 0.0005611672278338945\n",
      "LM_prob( went | cigarette )= 0.00019884668920262477\n",
      "LM_prob( to | went )= 0.0005955926146515784\n",
      "LM_prob( the | to )= 0.019489779749643478\n",
      "LM_prob( hallway | the )= 0.00013875398917718884\n",
      "LM_prob( after | hallway )= 0.0001990049751243781\n",
      "LM_prob( shaking | after )= 0.00019727756954034326\n",
      "LM_prob( the | shaking )= 0.0001990049751243781\n",
      "LM_prob( womans | the )= 0.00013875398917718884\n",
      "LM_prob( hand | womans )= 0.00019892580067634773\n",
      "LM_prob( END | hand )= 0.00019860973187686197\n",
      "calculate PT_prob for ['the', 'man'] ['adam'] = 1e-12\n",
      "tutu False ['the', 'man'] ['adam']\n",
      "d( 0 )= 1.0\n",
      "calculate PT_prob for ['understood'] ['anladı'] = 1e-12\n",
      "tutu True ['understood'] ['anladı']\n",
      "{\"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen', 'larvalardan']\": 1, \"['daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen', 'larvalardan', 'çıkıyorlardı']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen', 'larvalardan']\": 1, \"['oysa', 'daha', 'sonra', 'anlaşılacaktı', 'ki', 'etlerin', 'üzerindeki', 'kurtlar', 'kendiliklerinden', 'oluşmuyorlar', 'sineklerin', 'getirip', 'bıraktıkları', 'gözle', 'görülmeyen', 'larvalardan', 'çıkıyorlardı']\": 1}\n",
      "d( 1 )= 0.5\n",
      "calculate PT_prob for ['this'] ['bunu'] = 1e-12\n",
      "tutu True ['this'] ['bunu']\n",
      "{\"['kalplerini']\": 1, \"['cahiliye']\": 1, \"['aldatır']\": 1, \"['de']\": 8, \"['kaybedeceklerdir']\": 1, \"['kaybedeceklerdir', '']\": 1, \"['metadan']\": 1, \"['bir', 'metadan']\": 1, \"['ettikleri']\": 1, \"['ettikleri', 've']\": 1, \"['hayat']\": 1, \"['hayat', 'yaşamalarından']\": 1, \"['hayat', 'yaşamalarından', 'kaynaklanmaz']\": 1, \"['bir', 'hayat']\": 1, \"['bir', 'hayat', 'yaşamalarından']\": 1, \"['bir', 'hayat', 'yaşamalarından', 'kaynaklanmaz']\": 1, \"['hayatını']\": 1, \"['hayatını', 'onun']\": 1, \"['mutlaka']\": 1, \"['mutlaka', 'yaşamak']\": 1, \"['çok', 'önemli', 'bir', 'konudur']\": 1, \"['duygusal']\": 1, \"['yapı']\": 1, \"['yapı', 'başta']\": 1, \"['yapı', 'başta', 'kadınların']\": 1, \"['alışkanlıkları']\": 1, \"['alışkanlıkları', 'tartışmacı']\": 1, \"['alışkanlıkları', 'tartışmacı', 'bir']\": 1, \"['söylenme', 'alışkanlıkları']\": 1, \"['söylenme', 'alışkanlıkları', 'tartışmacı']\": 1, \"['söylenme', 'alışkanlıkları', 'tartışmacı', 'bir']\": 1, \"['beğendiği', 'şekilde', 'bir', 'hayat']\": 1, \"['allahın', 'beğendiği', 'şekilde', 'bir', 'hayat']\": 1, \"['oysa']\": 1, \"['bir']\": 1, \"['kesin', 'bir']\": 1, \"['da']\": 1, \"['da', 'sıkıntılı']\": 1, \"['da', 'sıkıntılı', 'bir']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale', 'getirmekten']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale', 'getirmekten', 'başka']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale', 'getirmekten', 'başka', 'bir']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale', 'getirmekten', 'başka', 'bir', 'işe']\": 1, \"['da', 'sıkıntılı', 'bir', 'hale', 'getirmekten', 'başka', 'bir', 'işe', 'yaramaz']\": 1, \"['nedenle', 'de']\": 1, \"['kuran']\": 1, \"['nedenle', 'de', 'mutlaka']\": 1, \"['nedenle', 'de', 'mutlaka', 'açmazdadırlar']\": 1, \"['olmasa']\": 1, \"['tanımı', 'olmasa']\": 1, \"['cahiliye', 'erkeklerinin']\": 1, \"['gerçek']\": 1, \"['vardır']\": 1, \"['vardır', 'bu']\": 1, \"['etme']\": 1, \"['bazen']\": 1, \"['de', 'sürekli']\": 1, \"['bütün']\": 1, \"['hayatındaki', 'bütün']\": 1, \"['dünya', 'hayatındaki', 'bütün']\": 1, \"['onların', 'dünya', 'hayatındaki', 'bütün']\": 1, \"['karakteri']\": 1, \"['karakteri', 'aynı']\": 1, \"['temizlikçilere']\": 1, \"['temizlikçilere', 'ya']\": 1, \"['temizlikçilere', 'ya', 'da']\": 1, \"['temizlikçilere', 'ya', 'da', 'odacılara']\": 1, \"['i̇şte']\": 1, \"['girdiği']\": 1, \"['girdiği', 'andan']\": 1, \"['asla']\": 1, \"['asla', 'ödün']\": 1, \"['asla', 'ödün', 'vermemelerinden']\": 1, \"['yerleri']\": 1, \"['yerleri', 'yoktur']\": 1, \"['mesleğinden']\": 1, \"['dünya']\": 2, \"['ve']\": 1, \"['zengin']\": 1, \"['zengin', 'çevrelerde']\": 1, \"['itibaren', 'zengin']\": 1, \"['itibaren', 'zengin', 'çevrelerde']\": 1, \"['yaşlardan', 'itibaren', 'zengin']\": 1, \"['yaşlardan', 'itibaren', 'zengin', 'çevrelerde']\": 1, \"['bu']\": 1, \"['bu', 'ahlakı']\": 1, \"['alıştıkları', 'bu']\": 1, \"['alıştıkları', 'bu', 'ahlakı']\": 1, \"['artık', 'alıştıkları', 'bu']\": 1, \"['artık', 'alıştıkları', 'bu', 'ahlakı']\": 1, \"['nedenle', 'rahatlık']\": 1, \"['nedenle', 'rahatlık', 'onu']\": 1, \"['dünya', 'hayatı']\": 1, \"['oysa', 'dünya', 'hayatı']\": 1, \"['için']\": 1, \"['kuranın']\": 1, \"['şöyle']\": 1, \"['anında']\": 1, \"['her', 'anında']\": 1, \"['hayatının', 'her', 'anında']\": 1, \"['imtihan', 'hayatının', 'her', 'anında']\": 1, \"['sığınmaya']\": 1, \"['allaha', 'sığınmaya']\": 1, \"['ve', 'allaha', 'sığınmaya']\": 1, \"['kolaydır']\": 1, \"['bu', 'propaganda', 'gerçeği']\": 1, \"['bu', 'propaganda', 'gerçeği', 'gizleyememektedir']\": 1, \"['ancak', 'bu', 'propaganda', 'gerçeği']\": 1, \"['ancak', 'bu', 'propaganda', 'gerçeği', 'gizleyememektedir']\": 1, \"['çıkıyordu']\": 1, \"['karşı', 'çıkıyordu']\": 1, \"['gerçeğine', 'karşı', 'çıkıyordu']\": 1, \"['hayatın']\": 1, \"['hayatın', 'kendiliğinden']\": 1, \"['ise', 'hayatın']\": 1, \"['ise', 'hayatın', 'kendiliğinden']\": 1, \"['amacı', 'yaratılışı', 'reddetmek']\": 1, \"['amacı', 'yaratılışı', 'reddetmek', 'olan']\": 1, \"['amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim']\": 1, \"['amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim', 'teorisini']\": 1, \"['temel', 'amacı', 'yaratılışı', 'reddetmek']\": 1, \"['temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan']\": 1, \"['temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim']\": 1, \"['temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim', 'teorisini']\": 1, \"['en', 'temel', 'amacı', 'yaratılışı', 'reddetmek']\": 1, \"['en', 'temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan']\": 1, \"['en', 'temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim']\": 1, \"['en', 'temel', 'amacı', 'yaratılışı', 'reddetmek', 'olan', 'evrim', 'teorisini']\": 1, \"['geyikleri']\": 1, \"['mekanizma', 'geyikleri']\": 1, \"['tam']\": 1, \"['tam', 'aksidir']\": 1, \"['öngörülerinin', 'tam']\": 1, \"['öngörülerinin', 'tam', 'aksidir']\": 1, \"['ancak', 'siz', 'bu', 'zifiri', 'karanlıkta', 'ışıklı', 'pırıl', 'pırıl', 'bir']\": 1, \"['ancak', 'siz', 'bu', 'zifiri', 'karanlıkta', 'ışıklı', 'pırıl', 'pırıl', 'bir', 'dünyayı']\": 1, \"['ancak', 'siz', 'bu', 'zifiri', 'karanlıkta', 'ışıklı', 'pırıl', 'pırıl', 'bir', 'dünyayı', 'seyretmektesiniz']\": 1, \"['kadar']\": 1, \"['yerin']\": 1, \"['yerin', 'iki']\": 1, \"['ayırttığı', 'yerin']\": 1, \"['ayırttığı', 'yerin', 'iki']\": 1, \"['geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki']\": 1, \"['geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki', 'en']\": 1, \"['geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki', 'en', 'zor']\": 1, \"['yılında', 'geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki']\": 1, \"['yılında', 'geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki', 'en']\": 1, \"['yılında', 'geçiyordu', 'ivan', 'ilyiçin', 'yaşamındaki', 'en', 'zor']\": 1, \"['gönül', 'eğlendirici', 'değilse']\": 1, \"['gönül', 'eğlendirici', 'değilse', 'bile']\": 1, \"['gönül', 'eğlendirici', 'değilse', 'bile', 'can']\": 1, \"['gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı']\": 1, \"['gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı', 'da']\": 1, \"['gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı', 'da', 'değildi']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse', 'bile']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse', 'bile', 'can']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı', 'da']\": 1, \"['çalışma', 'gönül', 'eğlendirici', 'değilse', 'bile', 'can', 'sıkıcı', 'da', 'değildi']\": 1}\n",
      "d( -2 )= 0.25\n",
      "calculate PT_prob for ['extinguished', 'his', 'cigarette'] ['sigarasını', 'söndürdü'] = 1e-12\n",
      "tutu False ['extinguished', 'his', 'cigarette'] ['sigarasını', 'söndürdü']\n",
      "d( 1 )= 0.5\n",
      "calculate PT_prob for ['went', 'to', 'the', 'hall'] ['hole', 'çıktı'] = 1e-12\n",
      "tutu False ['went', 'to', 'the', 'hall'] ['hole', 'çıktı']\n",
      "d( 3 )= 0.125\n",
      "calculate PT_prob for ['while', 'shaking', 'hands', 'with', 'the', 'woman'] ['kadının', 'elini', 'sıkarak'] = 1e-12\n",
      "tutu False ['while', 'shaking', 'hands', 'with', 'the', 'woman'] ['kadının', 'elini', 'sıkarak']\n",
      "d( -5 )= 0.03125\n",
      "LM_prob( the | START )= 0.0252014652014652\n",
      "LM_prob( man | the )= 0.00041626196753156655\n",
      "LM_prob( understood | man )= 0.0001968503937007874\n",
      "LM_prob( this | understood )= 0.00019876764062810574\n",
      "LM_prob( extinguished | this )= 0.00018375597206909226\n",
      "LM_prob( his | extinguished )= 0.0001990049751243781\n",
      "LM_prob( cigarette | his )= 0.0005611672278338945\n",
      "LM_prob( went | cigarette )= 0.00019884668920262477\n",
      "LM_prob( to | went )= 0.0005955926146515784\n",
      "LM_prob( the | to )= 0.019489779749643478\n",
      "LM_prob( hall | the )= 0.00041626196753156655\n",
      "LM_prob( while | hall )= 0.00019892580067634773\n",
      "LM_prob( shaking | while )= 0.00019817677368212446\n",
      "LM_prob( hands | shaking )= 0.0001990049751243781\n",
      "LM_prob( with | hands )= 0.0003971405877680699\n",
      "LM_prob( the | with )= 0.007555723460521345\n",
      "LM_prob( woman | the )= 0.00041626196753156655\n",
      "LM_prob( END | woman )= 0.0017772511848341231\n",
      "calculate PT_prob for ['the', 'man'] ['adam'] = 1e-12\n",
      "tutu False ['the', 'man'] ['adam']\n",
      "d( 0 )= 1.0\n",
      "calculate PT_prob for ['got'] ['anladı'] = 1e-12\n",
      "tutu False ['got'] ['anladı']\n",
      "d( 1 )= 0.5\n",
      "calculate PT_prob for ['it'] ['bunu'] = 0.012048192771084338\n",
      "d( -2 )= 0.25\n",
      "calculate PT_prob for ['and', 'put', 'the', 'cigarette', 'off'] ['sigarasını', 'söndürdü'] = 1e-12\n",
      "tutu False ['and', 'put', 'the', 'cigarette', 'off'] ['sigarasını', 'söndürdü']\n",
      "d( 1 )= 0.5\n",
      "calculate PT_prob for ['went', 'to', 'the', 'hallway'] ['hole', 'çıktı'] = 1e-12\n",
      "tutu False ['went', 'to', 'the', 'hallway'] ['hole', 'çıktı']\n",
      "d( 3 )= 0.125\n",
      "calculate PT_prob for ['shaking', 'the', 'hand', 'of', 'the', 'woman'] ['kadının', 'elini', 'sıkarak'] = 1e-12\n",
      "tutu False ['shaking', 'the', 'hand', 'of', 'the', 'woman'] ['kadının', 'elini', 'sıkarak']\n",
      "d( -5 )= 0.03125\n",
      "LM_prob( the | START )= 0.0252014652014652\n",
      "LM_prob( man | the )= 0.00041626196753156655\n",
      "LM_prob( got | man )= 0.0001968503937007874\n",
      "LM_prob( it | got )= 0.00019876764062810574\n",
      "LM_prob( and | it )= 0.002416806097787693\n",
      "LM_prob( put | and )= 0.0003190810465858328\n",
      "LM_prob( the | put )= 0.00039627501486031304\n",
      "LM_prob( cigarette | the )= 0.00013875398917718884\n",
      "LM_prob( off | cigarette )= 0.00019884668920262477\n",
      "LM_prob( went | off )= 0.00019857029388403494\n",
      "LM_prob( to | went )= 0.0005955926146515784\n",
      "LM_prob( the | to )= 0.019489779749643478\n",
      "LM_prob( hallway | the )= 0.00013875398917718884\n",
      "LM_prob( shaking | hallway )= 0.0001990049751243781\n",
      "LM_prob( the | shaking )= 0.0001990049751243781\n",
      "LM_prob( hand | the )= 0.00013875398917718884\n",
      "LM_prob( of | hand )= 0.00019860973187686197\n",
      "LM_prob( the | of )= 0.0389650392730633\n",
      "LM_prob( woman | the )= 0.00041626196753156655\n",
      "LM_prob( END | woman )= 0.0017772511848341231\n",
      "\u001b[1;1mBest translation for \n",
      "\" adam bunu anladı sigarasını söndürdü kadının elini sıkarak hole çıktı \"\u001b[0m\n",
      "according to Phrase-based Model with P(e|f) 1.0242838588060862e-130 :\n",
      "\" the man got it and put the cigarette off went to the hallway shaking the hand of the woman \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####### PHRASE BASED MODEL #######\n",
    "# alignment e:[f]\n",
    "examples_a = [{0: {0:[0], 1:[0], 2:[2], 3:[1], 4:[4], 5:[3], 6:[3], 7:[9], 8:[8], 9:[8], 10:[8], 11:[7], 12:[7], 13:[5], 14:[5],15:[6]}, 1: {0:[0], 1:[0], 2:[2], 3:[1], 4:[4], 5:[3], 6:[3], 7:[9], 8:[8], 9:[8], 10:[8], 11:[7], 12:[7], 13:[6], 14:[5],15:[5],16:[5]}, 2: {0:[0], 1:[0], 2:[2], 3:[1], 4:[4], 5:[4], 6:[3], 7:[3], 8:[4], 9:[9], 10:[8], 11:[8], 12:[8], 13:[7], 14:[6],15:[6],16:[5],17:[5],18:[5]}},\\\n",
    "{0: {0:[2], 1:[1], 2:[2], 3:[0], 4:[0], 5:[3,4,5], 6:[3,4,5], 7:[7], 8:[10], 9:[10], 10:[9], 11:[9], 12:[8], 13:[9], 14:[6]}, 1: {0:[2], 1:[1], 2:[2], 3:[0], 4:[0], 5:[5], 6:[5], 7:[5], 8:[4], 9:[4], 10:[7], 11:[6], 12:[10], 13:[10], 14:[9],15:[9],16:[8],17:[9]}, 2: {0:[2], 1:[1], 2:[2], 3:[0], 4:[0], 5:[3,4,5], 6:[3,4,5], 7:[3,4,5], 8:[7], 9:[6], 10:[10], 11:[10], 12:[10], 13:[10], 14:[9],15:[9],16:[8],17:[9]}, 3: {0:[4], 1:[3,4,5], 2:[3,4,5], 3:[3,4,5], 4:[3,4,5], 5:[2], 6:[1], 7:[1], 8:[1], 9:[2], 10:[7], 11:[10], 12:[6], 13:[10], 14:[9],15:[9],16:[8],17:[9]}},\\\n",
    "{0: {0:[1], 1:[0], 2:[0], 3:[3], 4:[3], 5:[3], 6:[2], 7:[2], 8:[5], 9:[4], 10:[4], 11:[18,19,20], 12:[18,19,20], 13:[6], 14:[7],15:[9],16:[10],17:[11],18:[12,13],19:[14],20:[14,15],21:[17],22:[17]}, 1: {0: [1], 1: [1], 2: [1], 3: [0], 4: [0], 5: [0], 6: [4,5], 7: [4,5], 8: [3], 9: [2], 10: [18,19,20], 11: [6],  12: [6], 13: [7], 14: [7], 15: [8], 16: [8], 17: [10], 18: [9], 19: [10], 20: [11], 21: [11], 22: [13],23:[12,13],24:[16],25:[14,15],26:[14,15],27:[14,15],28:[17],29:[17],30:[17]}}]\n",
    "\n",
    "# use IBM Model 2 for Viterbi alignments & combine them\n",
    "\n",
    "all_a_train = {}\n",
    "for si in range(0, len(f_train)):\n",
    "    e2f = viterbi_alignment(e_train[si], f_train[si], t_e2f, a_e2f)\n",
    "    f2e = viterbi_alignment(f_train[si], e_train[si], t_f2e, a_f2e)\n",
    "    a = combine(f2e, e2f)\n",
    "    all_a_train[si] = a\n",
    "all_a_train[len(f_train)-1] = examples_a[0][0]\n",
    "# extract phrases & estimate phrase translation probabilities\n",
    "\n",
    "max_phrase_len = 8\n",
    "phrase_counts = phrase_extraction(e_train, f_train, all_a_train, max_phrase_len)\n",
    "\n",
    "# train bigram language model LM\n",
    "unigram_counts, bigram_counts = count_grams(e_train)\n",
    "\n",
    "# testing\n",
    "# aligned_phrases format [{index: {e_to: (e_from, f_from, f_to)}}\n",
    "aligned_phrases = [{0: {1:(0,0,0), 2:(2,2,2), 3:(3,1,1), 6:(4,3,4), 10:(7,8,9), 15:(11,5,7)}, 1: {1:(0,0,0), 2:(2,2,2), 3:(3,1,1), 6:(4,3,4), 10:(7,8,9), 16:(11,5,7)}, 2: {1:(0,0,0), 2:(2,2,2), 3:(3,1,1), 8:(4,3,4), 12:(9,8,9), 18:(13,5,7)}}]\n",
    "for sentence in range(0, 1):#len(examples_f)):#TODO for all sentences & not only first after I filled aligned_phrases\n",
    "    f = examples_f[sentence]\n",
    "    best_e = ''\n",
    "    max_prob = 0.0\n",
    "    for index, e in examples_e[sentence].items():\n",
    "        a = examples_a[sentence][index]\n",
    "        phrases_a = aligned_phrases[sentence][index]\n",
    "        prob = prob_e_given_f(e, f, phrase_counts, unigram_counts, bigram_counts, phrases_a)\n",
    "        #print('p(', e, '|', f, ') =', prob,'\\n')\n",
    "        if prob >= max_prob:\n",
    "            max_prob = prob\n",
    "            best_e = e\n",
    "    print('\\x1b[1;1m'+'Best translation for \\n\"',' '.join(f),'\"'+'\\x1b[0m')\n",
    "    print('according to Phrase-based Model with P(e|f)',max_prob,':\\n\"',' '.join(best_e),'\"\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"['of', 'vanity', 'but']\", {\"['başına']\": 1})\n",
      "(\"['of', 'vanity']\", {\"['başına']\": 1})\n",
      "(\"['were', 'those', 'of', 'vanity', 'but', 'ivan', 'ilychs', 'greatest']\", {\"['tek', 'başına']\": 1})\n",
      "(\"['were', 'those', 'of', 'vanity', 'but', 'ivan', 'ilychs']\", {\"['tek', 'başına']\": 1})\n",
      "(\"['were', 'those', 'of', 'vanity', 'but', 'ivan']\", {\"['tek', 'başına']\": 1})\n",
      "(\"['were', 'those', 'of', 'vanity', 'but']\", {\"['tek', 'başına']\": 1})\n",
      "(\"['were', 'those', 'of', 'vanity']\", {\"['tek', 'başına']\": 1})\n",
      "(\"['were', 'those', 'of']\", {\"['tek', 'başına']\": 1})\n",
      "(\"['were', 'those']\", {\"['tek']\": 1})\n",
      "(\"['social', 'pleasures', 'were', 'those', 'of', 'vanity', 'but', 'ivan']\", {\"['tek', 'başına', 'tattığı']\": 1})\n",
      "1800\n",
      "['the', 'pleasures', 'connected', 'with', 'his', 'work', 'were', 'pleasures', 'of', 'ambition', 'his', 'social', 'pleasures', 'were', 'those', 'of', 'vanity', 'but', 'ivan', 'ilychs', 'greatest', 'pleasure', 'was', 'playing', 'bridge']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(phrase_counts.popitem())\n",
    "print(len(e_train))\n",
    "print(e_train[1799])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
